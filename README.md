# <center> Проект 3. EDA + Feature Engineering. Соревнование на Kaggle

## Оглавление
[1. Описание проекта](#Описание-проекта)  
[2. Какой кейс решаем?](#Какой-кейс-решаем)  
[3. Краткая информация о данных](#Краткая-информация-о-данных)  
[4. Этапы работы над проектом](#Этапы-работы-над-проектом)  
[5. Результат](#Результат-работы)    
[6. Выводы](#Выводы) 


### Описание проекта

В данном проекте попробуем решить свой первый настоящий кейс и создать первую модель, использующую алгоритмы машинного обучения.

### Какой кейс решаем?

Представим, что мы работаем дата-сайентистом в компании Booking. Одна из проблем компании — это нечестные отели, которые накручивают себе рейтинг. Одним из способов обнаружения таких отелей является построение модели, которая предсказывает рейтинг отеля. Если предсказания модели сильно отличаются от фактического результата, то, возможно, отель ведёт себя нечестно, и его стоит проверить.

Попробуем создать такую модель. 

:point_right: [К оглавлению](#Оглавление)

### Краткая информация о данных

 Данные к проекту были предоставлены организатором соревнования [Booking reviews](https://www.kaggle.com/competitions/sf-booking). 
Они представляют собой 3 датасета в формате *csv* с данными об отелях.

*Файлы для соревнования*:

- hotels_train.csv - набор данных для обучения
- hotels_test.csv - набор данных для оценки качества
- submission.csv - файл сабмишна в нужном формате

:point_right: [К оглавлению](#Оглавление)

### Этапы работы над проектом

Работа над проектом была разбита на несколько частей:

#### 1. Обзор и очистка данных

В начале мы загрули данные с *Kaggle*. Был сделан кратный обзор данных, удалены дубликаты. Для удобства работы и обработки признаков трейн и тест были  объеденены в один датасет.

#### 2. Обработка данных

После знакомства с данными, мы приступили непосредственно к обработке признаков. Признаки типа *object* были разобраны, преобразованы с бинарные или в числовые категориальные признаки. После работы с текстовыми признаками мы их удалили, поскольку модель машинного обучения может работать только с числами.

#### 3. Проверка на мультиколлениарность

На этом этапе была простроена тепловая карта корреляции признаков. Также мы отсеили несколько признаков с сильной корреляцией, чтобы не нагружать обучаемую модель малополезными вычислениями.

#### 4. Нормализация данных

В ходе исследования было выяснено, что наши данные не распределены нормально. Также одним из требованием к проекту было то, что мы не можем удалять строки из датасета. Получается, у нам не было возможности удалять выбросы данных. Поэтому разумным решением стало нормализация числовых данных с помощью *RobustScaler*. Тесты также показали эффективность данных преобразований - *Public Score* на *Kaggle* заметно уменьшился.

#### 5. Обучение модели

Прежде всего, для создания модели необходимо разделить датафрейм на набор данных, которые мы будем использовать для обучения модели, именуемый , и на целевую переменную — величину, значение которой мы будем предсказывать (в нашем случае это рейтинг отелей).

Далее каждый из полученных наборов мы делим на тренировочный (*train*, используется для обучения модели) и тестовый (test, используется для оценки точности модели). Такое деление осуществляется с помощью специального метода *train_test_split()* библиотеки sklearn. В параметрах метода (параметр *test_size*) мы указываем, какую часть исходного датафрейма нужно оставить для тестирования модели.

Сам процесс создания и тестирования модели занимает всего четыре строчки кода. В качестве алгоритма мы будем использовать популярный и довольно мощный алгоритм *RandomForestRegressor*. Он реализован в библиотеке *sklearn.*

:point_right: [К оглавлению](#Оглавление)

### Результат работы

Результат работы представлен в [jupiter-ноутбуке](https://github.com/romash23/project-3/blob/master/BaseLine_by_romash23.ipynb) и оформлен в соответствии с предоставленным шаблоном. С ноутбуком на *Kaggle* можно ознакомиться по [ссылке](https://www.kaggle.com/code/romash23/baseline-by-romash23). При работе с данным проектом удалось добиться метрики равной:

<img src=https://raw.githubusercontent.com/romash23/project-3/refs/heads/master/Score.jpg>

### Выводы

В данном проекте мы на практике мы попробовали свои силы на реальном кейсе компании Booking - построена модель машинного обучения для предсказания рейтинга отелей. Проведённый разведовательный анализ данных (*EDA*) позволил выявить и устранить дубликаты, а также преобразовать категориальные признаки в числовые, что улучшило качество данных для модели. Особое внимание уделялось борьбе с мультиколлинеарностью и нормализации признаков, что позволило повысить стабильность и точность модели.

Использование алгоритма *RandomForestRegressor* показало хорошую эффективность в задаче регрессии рейтингов, что подтверждается достигнутой метрикой качества на *Kaggle*. Проект продемонстрировал важность тщательной подготовки данных и грамотного инжиниринга признаков (*Feature Engineering*) для повышения точности предсказаний.

Таким образом, данный проект стал успешным примером полного цикла работы с данными - от их изучения и обработки до построения и оценки модели, что является ключевым навыком для дата-сайентиста и позволяет выявлять аномалии в бизнес-процессах, такие как нечестные отели.

:point_right: [К оглавлению](#Оглавление)
