# <center> Проект 3. EDA + Feature Engineering. Соревнование на Kaggle

## Оглавление
[1. Описание проекта](#Описание-проекта)  
[2. Какой кейс решаем?](#Какой-кейс-решаем)  
[3. Краткая информация о данных](#Краткая-информация-о-данных)  
[4. Этапы работы над проектом](#Этапы-работы-над-проектом)  
[5. Результат](#Результат-работы)    
[6. Выводы](#Выводы) 


### Описание проекта

В данном проекте попробуем решить свой первый настоящий кейс и создать первую модель, использующую алгоритмы машинного обучения.

### Какой кейс решаем?

Представим, что мы работаем дата-сайентистом в компании Booking. Одна из проблем компании — это нечестные отели, которые накручивают себе рейтинг. Одним из способов обнаружения таких отелей является построение модели, которая предсказывает рейтинг отеля. Если предсказания модели сильно отличаются от фактического результата, то, возможно, отель ведёт себя нечестно, и его стоит проверить.

Попробуем создать такую модель. 

### Краткая информация о данных

 Данные к проекту были предоставлены организатором соревнования [Booking reviews](https://www.kaggle.com/competitions/sf-booking). 
Они представляют собой 3 датасета в формате *csv* с данными об отелях.

*Файлы для соревнования*:

- hotels_train.csv - набор данных для обучения
- hotels_test.csv - набор данных для оценки качества
- submission.csv - файл сабмишна в нужном формате

:point_right: [К оглавлению](# Оглавление)


### Этапы работы над проектом

Работа над проектом была разбита на несколько частей:

#### 1. Обзор и очистка данных

В начале мы загрули данные с *Kaggle*. Был сделан кратный обзор данных, удалены дубликаты. Для удобства работы и обработки признаков трейн и тест были  объеденены в один датасет.

#### 2. Обработка данных

После знакомства с данными, мы приступили непосредственно к обработке признаков. Признаки типа *object* были разобраны, преобразованы с бинарные или в числовые категориальные признаки. После работы с текстовыми признаками мы их удалили, поскольку модель машинного обучения может работать только с числами.

#### 3. Проверка на мультиколлениарность

На этом этапе была простроена тепловая карта корреляции признаков. Также мы отсеили несколько признаков с сильной корреляцией, чтобы не нагружать обучаемую модель малополезными вычислениями.

#### 4. Нормализация данных

В ходе исследования было выяснено, что наши данные не распределены нормально. Также одним из требованием к проекту было то, что мы не можем удалять строки из датасета. Получается, у нам не было возможности удалять выбросы данных. Поэтому разумным решением стало нормализация числовых данных с помощью *RobustScaler*. Тесты также показали эффективность данных преобразований - *Public Score* на *Kaggle* заметно уменьшился.

#### 5. Обучение модели

Прежде всего, для создания модели необходимо разделить датафрейм на набор данных, которые мы будем использовать для обучения модели, именуемый , и на целевую переменную — величину, значение которой мы будем предсказывать (в нашем случае это рейтинг отелей).

Далее каждый из полученных наборов мы делим на тренировочный (*train*, используется для обучения модели) и тестовый (test, используется для оценки точности модели). Такое деление осуществляется с помощью специального метода *train_test_split()* библиотеки sklearn. В параметрах метода (параметр *test_size*) мы указываем, какую часть исходного датафрейма нужно оставить для тестирования модели.

Сам процесс создания и тестирования модели занимает всего четыре строчки кода. В качестве алгоритма мы будем использовать популярный и довольно мощный алгоритм *RandomForestRegressor*. Он реализован в библиотеке *sklearn.*

:point_right: [К оглавлению](# Оглавление)

### Результат работы

Результат работы представлен в [jupiter-ноутбуке](https://github.com/romash23/project-3/blob/master/BaseLine_by_romash23.ipynb) и оформлен в соответствии с предоставленным шаблоном. С ноутбуком на *Kaggle* можно ознакомиться по [ссылке](https://www.kaggle.com/code/romash23/baseline-by-romash23). При работе с данным проектом удалось добиться метрики равной:

### Выводы

В данном проекте мы на практике применили знания, полученные ранее: работа с библиотеками *psycopg2*, *requests*, *BeautifulSoup*, создание запросов к базам данных с помощью языка *SQL*. Одним из ключевых навыков датасайентиста оказалось знание SQL, что ж в данном проекте мы смогли удостовериться в его необходимости. Но также, мы узнали, что владения инструментами *SQL* и *Python* для специалиста-DS крайне важно, но недостаточно: в среднем для устройства на работу на должность ученого по данным нужно иметь в среднем 6,41 ключевой навык. Поэтому не стоит останавливаться на достигнутом, нас  ждет еще масса интересных заданий и увлекательных проектов :muscle:

:point_right: [К оглавлению](# Оглавление)
